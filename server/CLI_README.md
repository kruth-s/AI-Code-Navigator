# ğŸ¤– Akaza - Interactive Codebase Q&A CLI

Dynamic AI-powered tool to analyze any GitHub repository and answer questions about it.

## ğŸš€ Quick Start

### Option 1: Using the Launcher
```bash
run_cli.bat
```

### Option 2: Direct Python
```bash
python interactive_cli.py
```

## ğŸ“– How to Use

### Step 1: Ingest a Repository
1. Run the CLI
2. Choose option `1` (Ingest a new repository)
3. Enter any GitHub repository URL, for example:
   - `https://github.com/kruth-s/object-identity-ai-gcp`
   - `https://github.com/facebook/react`
   - `https://github.com/your-username/your-repo`

The system will:
- âœ… Clone the repository
- âœ… Extract and chunk code files
- âœ… Generate embeddings
- âœ… Upload to Pinecone vector database

### Step 2: Ask Questions
1. Choose option `2` (Ask a question)
2. Type your question in natural language:
   - "Where is authentication implemented?"
   - "How does the caching layer work?"
   - "What does the ghost context do?"
   - "Explain the main architecture"

The AI agent will:
- ğŸ” Search the vector database
- ğŸ§  Analyze relevant code
- ğŸ’¡ Provide a detailed answer

### Step 3: Switch Repositories
Want to analyze a different repo?
1. Choose option `1` again
2. Enter a new GitHub URL
3. The old data will be cleared automatically

## ğŸ¯ Example Session

```
ğŸ¤– Akaza - Interactive Codebase Q&A
======================================================================

ğŸ“Œ Options:
  1. Ingest a new repository
  2. Ask a question about current repository
  3. Exit

ğŸ‘‰ Enter choice (1/2/3): 1

ğŸ”— Enter GitHub repository URL: https://github.com/kruth-s/object-identity-ai-gcp

ğŸ“¥ Ingesting repository: https://github.com/kruth-s/object-identity-ai-gcp
======================================================================
ğŸ“‚ Cloning to E:\Github\Akaza\server\repos\object-identity-ai-gcp...
ğŸ“– Reading files...
âœ… Found 45 files
âœ‚ï¸  Splitting into chunks...
âœ… Created 289 chunks
ğŸ§  Generating embeddings...
â˜ï¸  Uploading to Pinecone...
   Batch 1/3 uploaded
   Batch 2/3 uploaded
   Batch 3/3 uploaded

âœ… Repository 'object-identity-ai-gcp' ingested successfully!

ğŸ‘‰ Enter choice (1/2/3): 2

â“ Ask about 'object-identity-ai-gcp': Where is ghost context used?

ğŸ¤” Question: Where is ghost context used?
======================================================================
ğŸ” Searching and analyzing...

ğŸ’¡ Answer:
----------------------------------------------------------------------
The ghost context is used in the ghost_signals.py file for detecting
and analyzing faint images using image processing, feature extraction,
and machine learning techniques...

ğŸ¯ Confidence: high
======================================================================
```

## ğŸ› ï¸ Technical Details

- **LLM**: Groq (llama-3.3-70b-versatile)
- **Embeddings**: HuggingFace (all-MiniLM-L6-v2)
- **Vector DB**: Pinecone (384 dimensions)
- **Agent Framework**: LangGraph

## ğŸ“ Notes

- Each new repository ingestion **clears previous data**
- Local repo clones are stored in `server/repos/` during ingestion
- All vector data is stored in Pinecone cloud
- Supports: `.py`, `.js`, `.ts`, `.jsx`, `.tsx`, `.md`, `.txt`, `.java`, `.go`, `.rs`, `.c`, `.cpp`, `.h`

## ğŸ”§ Configuration

Edit `.env` file:
```env
GROQ_API_KEY=your_groq_key
PINECONE_API_KEY=your_pinecone_key
PINECONE_INDEX=codey
```
